{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing : Spark SQL, Dataframes, Datasets \n",
    "suite (3) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing de Airlines Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.43.47:4044\n",
       "SparkContext available as 'sc' (version = 3.0.1, master = local[*], app id = local-1625091472724)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@25c9ae87\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    appName(\"Basic Transformations\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airlines_path: String = datasets/airlines_all.05p.csv\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val airlines_path = \"datasets/airlines_all.05p.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay,IsArrDelayed,IsDepDelayed\n",
      "1988,1,9,6,1348,1331,1458,1435,PI,942,NA,70,64,NA,23,17,SYR,BWI,273,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,YES\n",
      "1988,1,29,5,1339,1331,1442,1435,PI,942,NA,63,64,NA,7,8,SYR,BWI,273,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,YES\n",
      "1988,1,23,6,950,950,1041,1050,PI,943,NA,51,60,NA,-9,0,LGA,SYR,198,NA,NA,0,NA,0,NA,NA,NA,NA,NA,NO,NO\n",
      "1988,1,18,1,1124,1110,1213,1145,PI,943,NA,49,35,NA,28,14,SYR,BUF,134,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,YES\n",
      "1988,1,10,7,1503,1500,1602,1550,PI,944,NA,59,50,NA,12,3,JFK,UCA,191,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,YES\n",
      "1988,1,30,6,1500,1500,1558,1550,PI,944,NA,58,50,NA,8,0,JFK,UCA,191,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,NO\n",
      "1988,1,20,3,1750,1705,1900,1810,PI,944,NA,70,65,NA,50,45,SYR,BOS,264,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,YES\n",
      "1988,1,10,7,1616,1610,1632,1630,PI,944,NA,16,20,NA,2,6,UCA,SYR,37,NA,NA,0,NA,0,NA,NA,NA,NA,NA,YES,YES\n",
      "1988,1,30,6,1610,1610,1627,1630,PI,944,NA,17,20,NA,-3,0,UCA,SYR,37,NA,NA,0,NA,0,NA,NA,NA,NA,NA,NO,NO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head \"datasets/airlines_all.05p.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airlines_all: org.apache.spark.sql.DataFrame = [Year: string, Month: string ... 29 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val airlines_all = spark.\n",
    "    read.\n",
    "    option(\"header\",\"true\").\n",
    "    csv(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: string (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: string (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: string (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: string (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: string (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      " |-- IsArrDelayed: string (nullable = true)\n",
      " |-- IsDepDelayed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines_all.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airlines: org.apache.spark.sql.DataFrame = [Year: string, Month: string ... 7 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val airlines = airlines_all.\n",
    "    select(\"Year\", \"Month\", \"DayOfMonth\",\n",
    "           \"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \n",
    "           \"FlightNum\", \"IsArrDelayed\", \"IsDepDelayed\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+--------+--------+-------------+---------+------------+------------+\n",
      "|Year|Month|DayOfMonth|DepDelay|ArrDelay|UniqueCarrier|FlightNum|IsArrDelayed|IsDepDelayed|\n",
      "+----+-----+----------+--------+--------+-------------+---------+------------+------------+\n",
      "|1988|    1|         9|      17|      23|           PI|      942|         YES|         YES|\n",
      "|1988|    1|        29|       8|       7|           PI|      942|         YES|         YES|\n",
      "|1988|    1|        23|       0|      -9|           PI|      943|          NO|          NO|\n",
      "|1988|    1|        18|      14|      28|           PI|      943|         YES|         YES|\n",
      "|1988|    1|        10|       3|      12|           PI|      944|         YES|         YES|\n",
      "|1988|    1|        30|       0|       8|           PI|      944|         YES|          NO|\n",
      "|1988|    1|        20|      45|      50|           PI|      944|         YES|         YES|\n",
      "|1988|    1|        10|       6|       2|           PI|      944|         YES|         YES|\n",
      "|1988|    1|        30|       0|      -3|           PI|      944|          NO|          NO|\n",
      "|1988|    1|        22|      -5|      -7|           PI|      945|          NO|          NO|\n",
      "|1988|    1|        15|       7|      -1|           PI|      948|          NO|         YES|\n",
      "|1988|    1|         8|     100|     101|           PI|      948|         YES|         YES|\n",
      "|1988|    1|         2|       3|      -5|           PI|      948|          NO|         YES|\n",
      "|1988|    1|        25|      -1|      30|           PI|      948|         YES|          NO|\n",
      "|1988|    1|        18|      NA|      NA|           PI|      948|         YES|         YES|\n",
      "|1988|    1|         9|      49|      64|           PI|      948|         YES|         YES|\n",
      "|1988|    1|        29|       1|      11|           PI|      948|         YES|         YES|\n",
      "|1988|    1|        13|      14|       4|           PI|      950|         YES|         YES|\n",
      "|1988|    1|         3|      19|      17|           PI|      950|         YES|         YES|\n",
      "|1988|    1|        23|      -2|     -15|           PI|      950|          NO|          NO|\n",
      "+----+-----+----------+--------+--------+-------------+---------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir le décompte des vols qui partent en retard à l'origine et arrivent à destination tôt ou à l'heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Long = 44985\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 44985\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(col(\"IsDepDelayed\") === \"YES\" and col(\"IsArrDelayed\") === \"NO\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Long = 44985\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter($\"IsDepDelayed\" === \"YES\" and $\"IsArrDelayed\" === \"NO\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Long = 44985\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(airlines(\"IsDepDelayed\") === \"YES\" and airlines(\"IsArrDelayed\") === \"NO\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir le décompte des vols qui partent en retard de plus de 60 minutes par rapport à l'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Long = 12693\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(\"DepDelay > 60\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Long = 12693\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(col(\"DepDelay\") > 60).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Long = 12693\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter($\"DepDelay\" > 60).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: Long = 12693\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(airlines(\"DepDelay\") > 60).\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir le décompte des vols qui partent tôt ou à l'heure mais arrivent en retard d'au moins 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res9: Long = 17834\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(\"IsDepDelayed = 'NO' AND ArrDelay >= 15\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res10: Long = 17834\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(col(\"IsDepDelayed\") === \"NO\" and col(\"ArrDelay\") >= 15).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: Long = 17834\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter($\"IsDepDelayed\" === \"NO\" and $\"ArrDelay\" >= 15).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res12: Long = 17834\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    filter(airlines(\"IsDepDelayed\") === \"NO\" and airlines(\"ArrDelay\") >= 15).\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir le nombre de vols qui quittent les principaux aéroports suivants - ORD, DFW, ATL, LAX, SFO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Origin|\n",
      "+------+\n",
      "|   DFW|\n",
      "|   SFO|\n",
      "|   ATL|\n",
      "|   ORD|\n",
      "|   LAX|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines_all.\n",
    "    filter(\"Origin IN ('ORD', 'DFW', 'ATL', 'LAX', 'SFO')\").\n",
    "    select(\"Origin\").\n",
    "    distinct.\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res14: Long = 99082\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_all.\n",
    "    filter(\"Origin IN ('ORD', 'DFW', 'ATL', 'LAX', 'SFO')\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.col\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: Long = 99082\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_all.\n",
    "    filter(col(\"Origin\") isin (\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res16: Long = 99082\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_all.\n",
    "    filter($\"Origin\" isin (\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")).\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: Long = 99082\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_all.\n",
    "    filter(airlines_all(\"Origin\") isin (\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")).\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir le nombre de vols partis en retard entre le 1er janvier 2008 et le 9 janvier en utilisant FlightDate.\n",
    "La date doit être au format yyyyMMdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{lpad, concat, col}\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{lpad, concat, col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+--------+--------+-------------+---------+------------+------------+----------+\n",
      "|Year|Month|DayOfMonth|DepDelay|ArrDelay|UniqueCarrier|FlightNum|IsArrDelayed|IsDepDelayed|FlightDate|\n",
      "+----+-----+----------+--------+--------+-------------+---------+------------+------------+----------+\n",
      "|1988|    1|         9|      17|      23|           PI|      942|         YES|         YES|  19880109|\n",
      "|1988|    1|        29|       8|       7|           PI|      942|         YES|         YES|  19880129|\n",
      "|1988|    1|        23|       0|      -9|           PI|      943|          NO|          NO|  19880123|\n",
      "|1988|    1|        18|      14|      28|           PI|      943|         YES|         YES|  19880118|\n",
      "|1988|    1|        10|       3|      12|           PI|      944|         YES|         YES|  19880110|\n",
      "|1988|    1|        30|       0|       8|           PI|      944|         YES|          NO|  19880130|\n",
      "|1988|    1|        20|      45|      50|           PI|      944|         YES|         YES|  19880120|\n",
      "|1988|    1|        10|       6|       2|           PI|      944|         YES|         YES|  19880110|\n",
      "|1988|    1|        30|       0|      -3|           PI|      944|          NO|          NO|  19880130|\n",
      "|1988|    1|        22|      -5|      -7|           PI|      945|          NO|          NO|  19880122|\n",
      "|1988|    1|        15|       7|      -1|           PI|      948|          NO|         YES|  19880115|\n",
      "|1988|    1|         8|     100|     101|           PI|      948|         YES|         YES|  19880108|\n",
      "|1988|    1|         2|       3|      -5|           PI|      948|          NO|         YES|  19880102|\n",
      "|1988|    1|        25|      -1|      30|           PI|      948|         YES|          NO|  19880125|\n",
      "|1988|    1|        18|      NA|      NA|           PI|      948|         YES|         YES|  19880118|\n",
      "|1988|    1|         9|      49|      64|           PI|      948|         YES|         YES|  19880109|\n",
      "|1988|    1|        29|       1|      11|           PI|      948|         YES|         YES|  19880129|\n",
      "|1988|    1|        13|      14|       4|           PI|      950|         YES|         YES|  19880113|\n",
      "|1988|    1|         3|      19|      17|           PI|      950|         YES|         YES|  19880103|\n",
      "|1988|    1|        23|      -2|     -15|           PI|      950|          NO|          NO|  19880123|\n",
      "+----+-----+----------+--------+--------+-------------+---------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res19: Long = 0\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter(\"FlightDate LIKE '2008010%' AND IsDepDelayed = 'YES'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res20: Long = 0\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter(\"FlightDate BETWEEN '20080101' AND '20080109' AND IsDepDelayed = 'YES'\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: Long = 0\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter($\"FlightDate\" like \"2008010%\" and $\"IsDepDelayed\" === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: Long = 4629\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.\n",
    "    withColumn(\"FlightDate\", \n",
    "               concat(col(\"Year\"), \n",
    "                      lpad(col(\"Month\"), 2, \"0\"), \n",
    "                      lpad(col(\"DayOfMOnth\"), 2, \"0\")\n",
    "                     )\n",
    "              ).\n",
    "    filter($\"FlightDate\" between (\"20080101\", \"20080109\") and $\"IsDepDelayed\" === \"YES\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation et extractions d'informations dans retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problème**\n",
    "\n",
    "Obtenez tous les clients qui ont passé une commande d'un montant supérieur à 200.\n",
    "Les fichiers d'entrée sont des fichiers délimités par des virgules placés sous l'emplacement datasets/retail_db :\n",
    "\n",
    "datasets/retail_db/customers  \n",
    "datasets/retail_db/orders  \n",
    "datasets/retail_db/order_items  \n",
    "\n",
    "**Schéma pour les fichiers d'entrée**\n",
    "\n",
    "```Client\n",
    "Customer_id,customer_fname,customer_lname,customer_email,customer_password,customer_street,customer_city,customer_state,customer_zipcode\n",
    " \n",
    "Ordres\n",
    "Order_id,order_date,order_customer_id,order_status\n",
    " \n",
    "Orders_Item\n",
    "Order_item_id,Order_item_order_id,order_item_product_id,Order_item_quantity,Order_item_subtotal,Order_item_product_price\n",
    "```\n",
    "\n",
    "**Sortie :**\n",
    "\n",
    "La sortie doit être placée sous l'emplacement datasets/retail_db/output\n",
    "\n",
    "Le fichier de sortie doit être un fichier séparé par des tabulations\n",
    "\n",
    "La sortie doit avoir customer_fname,customer_lname,customer_city,order_amount.\n",
    "\n",
    "L'en-tête ci-dessous doit être ajouté à la sortie\n",
    "\n",
    "fname, lname, city, order_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture des donnees clients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customers: org.apache.spark.sql.DataFrame = [customer_id: int, customer_fname: string ... 7 more fields]\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val customers = spark.\n",
    "                read.\n",
    "                schema(\"\"\"customer_id INT, customer_fname STRING, customer_lname STRING, \n",
    "                customer_email STRING, customer_password STRING, customer_street STRING, \n",
    "                customer_city STRING, customer_state STRING, customer_zipcode STRING\"\"\").\n",
    "                option(\"sep\", \",\").\n",
    "                csv(\"datasets/retail_db/customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|customer_id|customer_fname|customer_lname|customer_email|customer_password|     customer_street|customer_city|customer_state|customer_zipcode|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|          1|       Richard|     Hernandez|     XXXXXXXXX|        XXXXXXXXX|  6303 Heather Plaza|  Brownsville|            TX|           78521|\n",
      "|          2|          Mary|       Barrett|     XXXXXXXXX|        XXXXXXXXX|9526 Noble Embers...|    Littleton|            CO|           80126|\n",
      "|          3|           Ann|         Smith|     XXXXXXXXX|        XXXXXXXXX|3422 Blue Pioneer...|       Caguas|            PR|           00725|\n",
      "|          4|          Mary|         Jones|     XXXXXXXXX|        XXXXXXXXX|  8324 Little Common|   San Marcos|            CA|           92069|\n",
      "|          5|        Robert|        Hudson|     XXXXXXXXX|        XXXXXXXXX|10 Crystal River ...|       Caguas|            PR|           00725|\n",
      "|          6|          Mary|         Smith|     XXXXXXXXX|        XXXXXXXXX|3151 Sleepy Quail...|      Passaic|            NJ|           07055|\n",
      "|          7|       Melissa|        Wilcox|     XXXXXXXXX|        XXXXXXXXX|9453 High Concession|       Caguas|            PR|           00725|\n",
      "|          8|         Megan|         Smith|     XXXXXXXXX|        XXXXXXXXX|3047 Foggy Forest...|     Lawrence|            MA|           01841|\n",
      "|          9|          Mary|         Perez|     XXXXXXXXX|        XXXXXXXXX| 3616 Quaking Street|       Caguas|            PR|           00725|\n",
      "|         10|       Melissa|         Smith|     XXXXXXXXX|        XXXXXXXXX|8598 Harvest Beac...|     Stafford|            VA|           22554|\n",
      "|         11|          Mary|       Huffman|     XXXXXXXXX|        XXXXXXXXX|    3169 Stony Woods|       Caguas|            PR|           00725|\n",
      "|         12|   Christopher|         Smith|     XXXXXXXXX|        XXXXXXXXX|5594 Jagged Ember...|  San Antonio|            TX|           78227|\n",
      "|         13|          Mary|       Baldwin|     XXXXXXXXX|        XXXXXXXXX|7922 Iron Oak Gar...|       Caguas|            PR|           00725|\n",
      "|         14|     Katherine|         Smith|     XXXXXXXXX|        XXXXXXXXX|5666 Hazy Pony Sq...|  Pico Rivera|            CA|           90660|\n",
      "|         15|          Jane|          Luna|     XXXXXXXXX|        XXXXXXXXX|    673 Burning Glen|      Fontana|            CA|           92336|\n",
      "|         16|       Tiffany|         Smith|     XXXXXXXXX|        XXXXXXXXX|      6651 Iron Port|       Caguas|            PR|           00725|\n",
      "|         17|          Mary|      Robinson|     XXXXXXXXX|        XXXXXXXXX|     1325 Noble Pike|       Taylor|            MI|           48180|\n",
      "|         18|        Robert|         Smith|     XXXXXXXXX|        XXXXXXXXX|2734 Hazy Butterf...|     Martinez|            CA|           94553|\n",
      "|         19|     Stephanie|      Mitchell|     XXXXXXXXX|        XXXXXXXXX|3543 Red Treasure...|       Caguas|            PR|           00725|\n",
      "|         20|          Mary|         Ellis|     XXXXXXXXX|        XXXXXXXXX|      4703 Old Route|West New York|            NJ|           07093|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.\n",
    "             read.\n",
    "             schema(\"\"\"order_id INT, order_date STRING, order_customer_id INT, order_status STRING\"\"\").\n",
    "             option(\"sep\", \",\").csv(\"datasets/retail_db/orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318            |COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00.0|7130             |COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00.0|4530             |COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00.0|2911             |PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00.0|5657             |PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00.0|5648             |PENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00.0|918              |PAYMENT_REVIEW |\n",
      "|12      |2013-07-25 00:00:00.0|1837             |CLOSED         |\n",
      "|13      |2013-07-25 00:00:00.0|9149             |PENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00.0|9842             |PROCESSING     |\n",
      "|15      |2013-07-25 00:00:00.0|2568             |COMPLETE       |\n",
      "|16      |2013-07-25 00:00:00.0|7276             |PENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00.0|2667             |COMPLETE       |\n",
      "|18      |2013-07-25 00:00:00.0|1205             |CLOSED         |\n",
      "|19      |2013-07-25 00:00:00.0|9488             |PENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00.0|9198             |PROCESSING     |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_items: org.apache.spark.sql.DataFrame = [order_item_id: int, order_item_order_id: int ... 4 more fields]\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val order_items = spark.\n",
    "                  read.\n",
    "                  schema(\"\"\"order_item_id INT, order_item_order_id INT, order_item_product_id INT, \n",
    "                  order_item_quantity INT, order_item_subtotal DOUBLE, order_item_product_price DOUBLE\"\"\").\n",
    "                  option(\"sep\", \",\").csv(\"datasets/retail_db/order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "|order_item_id|order_item_order_id|order_item_product_id|order_item_quantity|order_item_subtotal|order_item_product_price|\n",
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "|1            |1                  |957                  |1                  |299.98             |299.98                  |\n",
      "|2            |2                  |1073                 |1                  |199.99             |199.99                  |\n",
      "|3            |2                  |502                  |5                  |250.0              |50.0                    |\n",
      "|4            |2                  |403                  |1                  |129.99             |129.99                  |\n",
      "|5            |4                  |897                  |2                  |49.98              |24.99                   |\n",
      "|6            |4                  |365                  |5                  |299.95             |59.99                   |\n",
      "|7            |4                  |502                  |3                  |150.0              |50.0                    |\n",
      "|8            |4                  |1014                 |4                  |199.92             |49.98                   |\n",
      "|9            |5                  |957                  |1                  |299.98             |299.98                  |\n",
      "|10           |5                  |365                  |5                  |299.95             |59.99                   |\n",
      "|11           |5                  |1014                 |2                  |99.96              |49.98                   |\n",
      "|12           |5                  |957                  |1                  |299.98             |299.98                  |\n",
      "|13           |5                  |403                  |1                  |129.99             |129.99                  |\n",
      "|14           |7                  |1073                 |1                  |199.99             |199.99                  |\n",
      "|15           |7                  |957                  |1                  |299.98             |299.98                  |\n",
      "|16           |7                  |926                  |5                  |79.95              |15.99                   |\n",
      "|17           |8                  |365                  |3                  |179.97             |59.99                   |\n",
      "|18           |8                  |365                  |5                  |299.95             |59.99                   |\n",
      "|19           |8                  |1014                 |4                  |199.92             |49.98                   |\n",
      "|20           |8                  |502                  |1                  |50.0               |50.0                    |\n",
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jointure** avec les Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requete: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [fname: string, lname: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val requete = order_items.\n",
    "       groupBy($\"order_item_order_id\").\n",
    "       sum(\"order_item_subtotal\").\n",
    "       where(\" sum(order_item_subtotal) > 200\").\n",
    "       join(orders, $\"order_id\" === $\"order_item_order_id\").\n",
    "       join(customers, $\"order_customer_id\" === $\"customer_id\").\n",
    "       select($\"customer_fname\".as(\"fname\"),$\"customer_lname\".as(\"lname\"),$\"customer_city\".as(\"city\"), $\"sum(order_item_subtotal)\".as(\"order_amount\")).\n",
    "       orderBy($\"order_amount\".desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------------+------------------+\n",
      "|    fname|   lname|           city|      order_amount|\n",
      "+---------+--------+---------------+------------------+\n",
      "| Victoria|   Smith|         Caguas|3449.9100000000003|\n",
      "|     Mary|Anderson|        Augusta|2859.8900000000003|\n",
      "| Samantha|   Smith|       Palatine|           2839.91|\n",
      "|   Daniel|   Smith|         Caguas|           2779.86|\n",
      "|     Mary|    Lane|         Caguas|            2699.9|\n",
      "|  Phillip|   Smith|       Amarillo|           2629.92|\n",
      "|   Teresa|    Gray|         Caguas|           2629.92|\n",
      "|Catherine| Hawkins|         Caguas|            2629.9|\n",
      "|    Amber|Sheppard|         Caguas|           2399.96|\n",
      "|  Matthew|   Smith|        Seattle|           2399.95|\n",
      "|     Mary|   Clark|      Frankfort|           2349.89|\n",
      "|     Mary|Cantrell|         Caguas|           2329.94|\n",
      "|  Richard|   Perry|          Bronx|           2299.96|\n",
      "|    Helen|   Smith|         Caguas|           2259.95|\n",
      "|  Charles|  Rogers|      San Diego|           2199.99|\n",
      "|     Mary|Harrison|         Caguas|           2149.99|\n",
      "|     Lisa|  Harper|Fort Lauderdale|            2039.8|\n",
      "|  Tiffany|Caldwell|  Silver Spring|           1999.88|\n",
      "|     Mary|  Miller|         Caguas|           1979.83|\n",
      "|     Mary|   Stein|       Mililani|            1899.9|\n",
      "+---------+--------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "requete.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "requete.write.mode(\"overwrite\").option(\"header\", \"true\").option(\"sep\", \"\\t\").format(\"csv\").save(\"datasets/retail_db/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+\n",
      "|order_item_order_id|sum(order_item_subtotal)|\n",
      "+-------------------+------------------------+\n",
      "|                148|                  479.99|\n",
      "|                463|       829.9200000000001|\n",
      "|                496|      441.95000000000005|\n",
      "|               1088|      249.97000000000003|\n",
      "|               1580|                  299.95|\n",
      "|               1591|                  439.86|\n",
      "|               1645|      1509.7900000000002|\n",
      "|               2366|                  299.97|\n",
      "|               2659|       724.9100000000001|\n",
      "|               2866|                  569.96|\n",
      "|               3175|                  209.97|\n",
      "|               3794|                  299.95|\n",
      "|               3918|       829.9300000000001|\n",
      "|               3997|                  579.95|\n",
      "|               4818|                  399.98|\n",
      "|               5156|                 1199.93|\n",
      "|               5300|                  759.85|\n",
      "|               5803|       764.8599999999999|\n",
      "|               6336|                  459.97|\n",
      "|               6357|      429.95000000000005|\n",
      "+-------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.\n",
    "       groupBy($\"order_item_order_id\").\n",
    "       sum(\"order_item_subtotal\").\n",
    "       where(\" sum(order_item_subtotal) > 200\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons reprendre le meme exercice avec Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abords on crée des tables temporaires à partir des dataframes avec `.createTempView` ou `.createOrReplaceTempView`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items.createOrReplaceTempView(\"order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlrequete: org.apache.spark.sql.DataFrame = [fname: string, lname: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlrequete = spark.sql(\"SELECT customer_fname as fname, customer_lname as lname, customer_city as city, order_amount \" +\n",
    "        \"FROM (SELECT order_item_order_id, sum(order_item_subtotal) as order_amount  FROM order_items  GROUP BY \" +\n",
    "        \"order_item_order_id HAVING sum(order_item_subtotal) > 200)\"+\n",
    "        \"JOIN orders ON order_id = order_item_order_id JOIN customers ON order_customer_id = customer_id \" +\n",
    "        \"ORDER BY order_amount DESC \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------------+------------------+\n",
      "|    fname|   lname|           city|      order_amount|\n",
      "+---------+--------+---------------+------------------+\n",
      "| Victoria|   Smith|         Caguas|3449.9100000000003|\n",
      "|     Mary|Anderson|        Augusta|2859.8900000000003|\n",
      "| Samantha|   Smith|       Palatine|           2839.91|\n",
      "|   Daniel|   Smith|         Caguas|           2779.86|\n",
      "|     Mary|    Lane|         Caguas|            2699.9|\n",
      "|   Teresa|    Gray|         Caguas|           2629.92|\n",
      "|  Phillip|   Smith|       Amarillo|           2629.92|\n",
      "|Catherine| Hawkins|         Caguas|            2629.9|\n",
      "|    Amber|Sheppard|         Caguas|           2399.96|\n",
      "|  Matthew|   Smith|        Seattle|           2399.95|\n",
      "|     Mary|   Clark|      Frankfort|           2349.89|\n",
      "|     Mary|Cantrell|         Caguas|           2329.94|\n",
      "|  Richard|   Perry|          Bronx|           2299.96|\n",
      "|    Helen|   Smith|         Caguas|           2259.95|\n",
      "|  Charles|  Rogers|      San Diego|           2199.99|\n",
      "|     Mary|Harrison|         Caguas|           2149.99|\n",
      "|     Lisa|  Harper|Fort Lauderdale|            2039.8|\n",
      "|  Tiffany|Caldwell|  Silver Spring|           1999.88|\n",
      "|     Mary|  Miller|         Caguas|           1979.83|\n",
      "|     Mary|   Stein|       Mililani|            1899.9|\n",
      "+---------+--------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlrequete.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlrequete.write.mode(\"overwrite\").option(\"header\", \"true\").option(\"sep\", \"\\t\").format(\"csv\").save(\"datasets/retail_db/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
